{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32NIMWNdsbOj",
        "outputId": "1b599656-0aae-4e9d-a740-6dd16bd9191e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CAPSTONE PROJECT/expected_ctc.csv')\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Rows:\", df.shape[0])\n",
        "print(\"Columns:\", df.shape[1])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "i2_THoyXtIVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "eUwgfc33tOx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSummary Statistics:\")\n",
        "display(df.describe().T)"
      ],
      "metadata": {
        "id": "85FkMggNtPj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum().sort_values(ascending=False).head(10))"
      ],
      "metadata": {
        "id": "2o1zXo-EtlEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "\n",
        "target = 'Expected_CTC'\n",
        "df['Expected_CTC_log'] = np.log1p(df[target])\n",
        "\n",
        "num_cols = df.select_dtypes(include=['number']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
        "df[cat_cols] = df[cat_cols].fillna('Unknown')\n",
        "\n",
        "print(\"Data cleaning completed!\")"
      ],
      "metadata": {
        "id": "Mp2XONrstsD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Total_Experience' in df.columns and 'Total_Experience_in_field_applied' in df.columns:\n",
        "    df['Experience_Gap'] = df['Total_Experience'] - df['Total_Experience_in_field_applied']\n",
        "\n",
        "if 'Inhand_Offer' in df.columns:\n",
        "    df['Inhand_Offer_Flag'] = df['Inhand_Offer'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "print(\"Feature engineering completed!\")"
      ],
      "metadata": {
        "id": "2f3MxsGqtuma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "print(\"Categorical features encoded successfully!\")"
      ],
      "metadata": {
        "id": "-wUz7nHQtxkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[target, 'Expected_CTC_log'])\n",
        "y = df['Expected_CTC_log']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train-Test split completed!\")\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Testing samples :\", X_test.shape[0])"
      ],
      "metadata": {
        "id": "UWbVP7TdtziA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor(n_estimators=100,max_depth=20,max_features='sqrt',random_state=42,n_jobs=-1 )\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_log = model.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_true = np.expm1(y_test)\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = mean_squared_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"Model training completed!\")\n",
        "print(f\"MAE : {mae:,.2f}\")\n",
        "print(f\"RMSE: {rmse:,.2f}\")\n",
        "print(f\"RÂ²  : {r2:.3f}\")"
      ],
      "metadata": {
        "id": "tOFZJoTnt1IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=imp.head(15), y=imp.head(15).index)\n",
        "plt.title(\"Top 15 Important Features\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rp02Cs9Bt5Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_features = ['Gender', 'Department', 'Education']\n",
        "\n",
        "fairness_features = [col for col in fairness_features if col in df.columns]\n",
        "\n",
        "if fairness_features:\n",
        "    test_df = X_test.copy()\n",
        "    test_df['Actual_CTC'] = np.expm1(y_test)\n",
        "    test_df['Predicted_CTC'] = np.expm1(model.predict(X_test))\n",
        "\n",
        "    for feature in fairness_features:\n",
        "        test_df[feature] = df.loc[X_test.index, feature]\n",
        "\n",
        "        fairness = test_df.groupby(feature)[['Actual_CTC', 'Predicted_CTC']].mean()\n",
        "        fairness['Difference'] = fairness['Predicted_CTC'] - fairness['Actual_CTC']\n",
        "\n",
        "        print(f\"\\nFairness Check by {feature}:\")\n",
        "        print(fairness.sort_values('Difference', ascending=False))\n",
        "else:\n",
        "    print(\"No categorical features found for fairness check.\")\n"
      ],
      "metadata": {
        "id": "AbwbO7est_Tr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}